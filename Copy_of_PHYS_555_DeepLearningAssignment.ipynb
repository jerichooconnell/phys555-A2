{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerichooconnell/phys555-A2/blob/master/Copy_of_PHYS_555_DeepLearningAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mamydDTWBBne"
      },
      "source": [
        "# Assignment Deep Learning\n",
        "\n",
        "Please complete the two sections. Submit a copy of the notebook when run entirely, either by uploading the notebook or a restricted shared link\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A - Concepts (40%)\n",
        "\n",
        "Answer each question as concisely as you can."
      ],
      "metadata": {
        "id": "7B92r1hDxpXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **For a multi-class classification neural network, what kind of activation would you use in the output layer and which loss function would you select?**\n",
        "\n",
        "Softmax and cross entropy"
      ],
      "metadata": {
        "id": "a-mQbyVncel8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Give two possible methods to avoid overfitting a deep learning model. Explain very briefly how each help mitigating overfitting.**\n",
        "\n",
        "Regularization\n",
        "Dataset variability"
      ],
      "metadata": {
        "id": "c46lORglceU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **What is the main issue the attention mechanism help with if you want to use to translate sequences**\n",
        "\n",
        "% your answer"
      ],
      "metadata": {
        "id": "WzTqrbOkxLgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. You have a dataset made of 1M audio recordings. Each recording has exactly the same number of samples, and consists of one instrument.\n",
        "Your task would be to obtain the type of instruments used in all the recordings.\n",
        "\n",
        "  You are in luck, you also have the type of instrument for 10,000 of the recordings, and you know there is no other type of instrument in the other recordings. \n",
        "\n",
        "  Briefly explain how to formulate the problem from a machine learning perspective, i.e.:\n",
        "    - 5.1. **How would you split your data set?**\n",
        "    - 5.2. **Is a neural network a good choice for the problem? What type of NN?**\n",
        "    - 5.3. **If you are using a NN, indicate the what is the last layer of your NN, your activation function, and which loss you would be using to train the NN.**\n",
        "\n",
        "% your answer"
      ],
      "metadata": {
        "id": "Ly6kjnStcd6R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V62vnQ6pBBnh"
      },
      "source": [
        "## 2. Applications (60%)\n",
        "\n",
        "#### **Noise2Noise**\n",
        "\n",
        "In this part of the assignment, we will implement the training of \"Noise2Noise: Learning Image Restoration without Clean Data\". \n",
        "Most of the network is implemented. You will have to answer a few questions, and implement a few things only.\n",
        "\n",
        "\n",
        "![](https://research.nvidia.com/sites/default/files/publications/n2n-representative_0.png)\n",
        "\n",
        "\n",
        "The one line summary of the method is the following: we can learn to remove noise from images by training a UNet between two noisy versions of the same image.\n",
        "\n",
        "\n",
        "If we had a set of noisy but also ground-truth, noiseless images of the same objects, we can imagine to learn a neural network to perform a mapping between the noisy and the clean variant. But what if we only have noisy images? This is the point of Noise2Noise.\n",
        "\n",
        "When one has set of noisy images where the only difference is an additive and independent noise realisation, then the Noise2Noise network can produce images with much reduced noise level. One could use those _denoised_ images to detect very faint features.\n",
        "\n",
        "See the [original paper](https://arxiv.org/abs/1803.04189) if you are interested in more details. Above is a figure from the paper showing a MRI denoised image with Noise2Noise (2nd column) which can get very similar signal to noise level as if the dataset was trained with noiseless images as targets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given one image $\\mathbf{x}$ with two additive and unbiased noise realisations $Ïµ$ ab $\\delta$, i.e.:\n",
        "$\\mathbf{y}=\\mathbf{x}+\\epsilon$ and $\\tilde{\\mathbf{y}} = \\mathbf{x} + \\delta$. We can formulate our denoising task as a _regression_ problem,finding a network $f_\\theta$ such that $\\mathbf{\\tilde{y}}$\n",
        "$$\n",
        "\\hat{\\theta} = \\arg\\min_\\theta \\mathbb{E}\\Vert \\mathbf{\\tilde{y}} - \\mathbf{y} \\Vert^2\n",
        "$$"
      ],
      "metadata": {
        "id": "lIhgBqkAn1vq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Show that the solution is unbiased when using $L_2$ for a loss function, for two additive and _independent_ noises, in other word**:\n",
        "\n",
        "$$\n",
        "\\arg\\min_\\theta \\mathbb{E}\\left[ \\Vert f_\\theta(\\mathbf{x}+\\epsilon) - (\\mathbf{x}+\\delta)\\Vert^2 \\right] = \\arg\\min_\\theta \\mathbb{E}\\left[ \\Vert f_\\theta(\\mathbf{x}+\\epsilon) - \\mathbf{x}\\Vert^2 \\right]\n",
        "$$\n",
        "\n",
        "\n",
        "% your answer\n",
        "\n"
      ],
      "metadata": {
        "id": "1tw1qSlMRikF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK_QMphIBBni"
      },
      "source": [
        "\n",
        "\n",
        "Noise2Noise is a UNet, a fully convolutional (no dense layers) neural network. We will code it below and you will have to comment and modify.\n",
        "\n",
        "\n",
        "First, let's do the boiler plates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRwowvdlBBni"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%load_ext tensorboard\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "# for image i/o and metrics\n",
        "from PIL import Image\n",
        "import imageio\n",
        "from skimage.metrics import peak_signal_noise_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kSFOET-BBnt"
      },
      "outputs": [],
      "source": [
        "# Fetching the device that will be used throughout this notebook\n",
        "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
        "print(\"Using device\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njh2lod8BBnk"
      },
      "source": [
        "## Data loading and preprocessing\n",
        "\n",
        "In order to train and validate our model, we will use natural images from the [VDSR dataset](https://cv.snu.ac.kr/research/VDSR). \n",
        "\n",
        "The images are noiseless but we will add artificial noise.\n",
        "First let's fetch the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RR86-hhJBBnk"
      },
      "outputs": [],
      "source": [
        "!wget --no-clobber https://cv.snu.ac.kr/research/VDSR/train_data.zip && mkdir -p train && unzip -qq train_data.zip -d train\n",
        "!ls -1 train | wc \n",
        "# run twice the cell if you get an error "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-clobber https://cv.snu.ac.kr/research/VDSR/test_data.zip  && mkdir -p valid && unzip -qq test_data.zip -d valid\n",
        "!ls -1 valid | wc \n",
        "# rerun if you get an error "
      ],
      "metadata": {
        "id": "hr4DtO8M0zmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = 'train'\n",
        "valid_dir = 'valid'"
      ],
      "metadata": {
        "id": "zU8fgAHAgDw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZBxttazBBnl"
      },
      "source": [
        "We first create a custom `Dataset`  class for loading all the images from disk and apply noise functions. The data is composed of various formats (bmp, jpg,...) and various sizes. We are cropping the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOekyoKjBBnl"
      },
      "outputs": [],
      "source": [
        "# default noise model: does not add noise.\n",
        "noiseless = lambda x: (x, x)\n",
        "\n",
        "class NoisyImages(Dataset):\n",
        "\n",
        "    def __init__(self, img_dir, add_noise=noiseless, crop_size=256):\n",
        "\n",
        "        suffixes = (\".jpeg\", \".jpg\", \".png\", \".bmp\")\n",
        "        self.image_paths = [p for p in Path(img_dir).glob(\"**/*\") if p.suffix.lower() in suffixes]\n",
        "        \n",
        "        self.add_noise = add_noise\n",
        "        \n",
        "        # the ToTensor converts a numpy array (H,W,C) in the range [0,255]\n",
        "        # to a torch tensor(C,H,W) in the range [0,1]\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.RandomCrop(crop_size, pad_if_needed=True, padding_mode='reflect'),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        \n",
        "    # number of samples in the DataSet\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    # load image given an index of the sample\n",
        "    def __getitem__(self, idx):\n",
        "  \n",
        "        img = imageio.imread(self.image_paths[idx])\n",
        "\n",
        "        # here we assume a 3-channel (RGB) image.\n",
        "        # single-channel images will fill other channels with a copy\n",
        "        if img.ndim == 2:\n",
        "            img = np.stack([img, img, img], axis=2)\n",
        "        elif img.shape[2] == 1:\n",
        "            img = np.concatenate([img, img, img], axis=2)\n",
        "\n",
        "        # convert to PIL image array and transform it\n",
        "        img = Image.fromarray(img)\n",
        "        img = self.transforms(img)\n",
        "\n",
        "        # offset the output transformed tensor from [0,1] to [-0.5,0.5] \n",
        "        img = img - 0.5\n",
        "        \n",
        "        # apply the noise function which returns a source and target image\n",
        "        return self.add_noise(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sPMatpKBBnm"
      },
      "source": [
        "Let us create training dataset and show some of the images. First some usual display functions to help visualizing our samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQrwmPTYBBnn"
      },
      "outputs": [],
      "source": [
        "# converts torch tensor between [-0.5,0.5] into a uint8 tensor\n",
        "def clip_to_uint8(x):\n",
        "    return torch.clamp((x + 0.5) * 255.0 + 0.5, 0, 255).type(torch.uint8)\n",
        "\n",
        "# plot a sample of two noisy images\n",
        "def show_random_sample(dataset):\n",
        "    idx = np.random.randint(0, len(dataset))\n",
        "    source, target = dataset[idx]\n",
        "\n",
        "    # convert (C,H,W) to (H,W,C) and to uint8\n",
        "    source = np.transpose(source, (1, 2, 0)) \n",
        "    target = np.transpose(target, (1, 2, 0))\n",
        "\n",
        "    source = clip_to_uint8(source)\n",
        "    target = clip_to_uint8(target)\n",
        "    \n",
        "    f, axarr = plt.subplots(1, 2)\n",
        "    axarr[0].imshow(source)\n",
        "    axarr[1].imshow(target)\n",
        "    _ = [ax.axis('off') for ax in axarr]\n",
        "    print(f'Image size is {source.shape}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5S0WvrjBBnn"
      },
      "outputs": [],
      "source": [
        "# lets check some samples images out\n",
        "train_data = NoisyImages(train_dir)\n",
        "show_random_sample(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP_R1UgJBBno"
      },
      "source": [
        "We need to produce noise. First case is Gaussian noise. We randomize the noise standard deviation  $\\sigma \\in [0, 50]$ separately for each training example. We need the noise function to add noise twice for source and target image separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI5m5XzIBBnp"
      },
      "outputs": [],
      "source": [
        "class AddGaussianNoise:\n",
        "    def __init__(self, sigma_range):\n",
        "        self.minval, self.maxval = sigma_range\n",
        "        self.minval = self.minval / 255\n",
        "        self.maxval = self.maxval / 255\n",
        "\n",
        "    def __call__(self, x):\n",
        "        sigma = (self.maxval - self.minval) * torch.rand(1) + self.minval\n",
        "        return x + torch.randn(x.size()) * sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rexp-t6YBBnp"
      },
      "outputs": [],
      "source": [
        "add_noise_train = AddGaussianNoise((0, 200))\n",
        "\n",
        "# add Gaussian noise with different standard deviation.\n",
        "train_noise = lambda x: (add_noise_train(x), add_noise_train(x))\n",
        "\n",
        "train_data = NoisyImages(train_dir, add_noise=train_noise)\n",
        "train_loader = DataLoader(train_data, batch_size=4, shuffle=True)\n",
        "\n",
        "# same for validation set\n",
        "add_noise_valid = AddGaussianNoise((100, 100))\n",
        "\n",
        "valid_noise = lambda x: (add_noise_valid(x), x)\n",
        "\n",
        "valid_data = NoisyImages(valid_dir, add_noise=valid_noise)\n",
        "valid_loader = DataLoader(valid_data, batch_size=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ev6hs_wWBBnq"
      },
      "outputs": [],
      "source": [
        "# replay the cell several times\n",
        "show_random_sample(train_data)\n",
        "show_random_sample(valid_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Why are the validation set target images noiseless?**\n",
        "\n",
        "% your answer"
      ],
      "metadata": {
        "id": "lQUQwy277C25"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEY6JB91BBnq"
      },
      "source": [
        "## Neural Network Architecture \n",
        "\n",
        "We are going to build almost the same UNet as the paper suggests.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Noise2Noise(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=3):\n",
        "\n",
        "        super(Noise2Noise, self).__init__()\n",
        "\n",
        "        # Layers: enc_conv0, enc_conv1, pool1\n",
        "        self._block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 48, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Conv2d(48, 48, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        # Layers: enc_conv(i), pool(i); i=2..5\n",
        "        self._block2 = nn.Sequential(\n",
        "            nn.Conv2d(48, 48, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        # Layers: enc_conv6, upsample5\n",
        "        self._block3 = nn.Sequential(\n",
        "            nn.Conv2d(48, 48, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.ConvTranspose2d(48, 48, kernel_size=3, stride=2, padding=1, output_padding=1))\n",
        "\n",
        "        # Layers: dec_conv5a, dec_conv5b, upsample4\n",
        "        self._block4 = nn.Sequential(\n",
        "            nn.Conv2d(96, 96, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Conv2d(96, 96, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        "\n",
        "        # Layers: dec_deconv(i)a, dec_deconv(i)b, upsample(i-1); i=4..2\n",
        "        self._block5 = nn.Sequential(\n",
        "            nn.Conv2d(144, 96, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Conv2d(96, 96, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.ConvTranspose2d(96, 96, kernel_size=3, stride=2, padding=1, output_padding=1))\n",
        "\n",
        "        # Layers: dec_conv1a, dec_conv1b, dec_conv1c,\n",
        "        self._block6 = nn.Sequential(\n",
        "            nn.Conv2d(96 + in_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Conv2d(32, out_channels, kernel_size=3, padding=1))\n",
        "        \n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight.data)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Encoder\n",
        "        pool1 = self._block1(x)\n",
        "        pool2 = self._block2(pool1)\n",
        "        pool3 = self._block2(pool2)\n",
        "        pool4 = self._block2(pool3)\n",
        "        pool5 = self._block2(pool4)\n",
        "\n",
        "        # Decoder\n",
        "        upsample5 = self._block3(pool5)\n",
        "        concat5 = torch.cat((upsample5, pool4), dim=1)\n",
        "\n",
        "        upsample4 = self._block4(concat5)\n",
        "        concat4 = torch.cat((upsample4, pool3), dim=1)\n",
        "        \n",
        "        upsample3 = self._block5(concat4)\n",
        "        concat3 = torch.cat((upsample3, pool2), dim=1)\n",
        "        \n",
        "        upsample2 = self._block5(concat3)\n",
        "        concat2 = torch.cat((upsample2, pool1), dim=1)\n",
        "        \n",
        "        upsample1 = self._block5(concat2)\n",
        "        concat1 = torch.cat((upsample1, x), dim=1)\n",
        "\n",
        "        return self._block6(concat1)"
      ],
      "metadata": {
        "id": "8q_dICvAk01q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Architecture understanding:\n",
        "\n",
        "> a. **What is the activation of the output layer? Why?**\n",
        "\n",
        "> b. **Is there any skip connection in the network? If yes, where?**\n",
        "\n",
        "> c. **Why do we have padding=1 in the encoder layers?**\n",
        "\n",
        "> d. **Which layer is reducing the dimension of the ?**\n",
        "\n",
        "\n",
        "% your answers"
      ],
      "metadata": {
        "id": "N3CEkm01J4YY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2iZinLWBBnr"
      },
      "source": [
        "Check the network is working with a single forward pass on a random image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kcjCnnnBBnr"
      },
      "outputs": [],
      "source": [
        "model = Noise2Noise(in_channels=3, out_channels=3)\n",
        "\n",
        "idx = np.random.randint(0, len(train_data))\n",
        "img = train_data[idx][0]\n",
        "output = model(img.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Now our training and validation routines"
      ],
      "metadata": {
        "id": "b9cWQiLSPBse"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQravEVCBBns"
      },
      "outputs": [],
      "source": [
        "# apply training for one epoch\n",
        "def train_model(model, loader, optimizer, criterion,\n",
        "                epoch, log_interval=100, tb_logger=None):\n",
        "\n",
        "    # set the model to train mode\n",
        "    model.train()\n",
        "\n",
        "    # iterate over the batches of this epoch\n",
        "    for batch_idx, (x, y) in enumerate(loader):\n",
        "\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # apply model, calculate loss and run backwards pass\n",
        "        prediction = model(x)\n",
        "        loss = criterion(prediction, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # log to notebook\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                  epoch, batch_idx * len(x),\n",
        "                  len(loader.dataset),\n",
        "                  100. * batch_idx / len(loader), loss.item()))\n",
        "\n",
        "            # log loss and images to tensorboard\n",
        "            if tb_logger is not None:\n",
        "                step = epoch * len(loader) + batch_idx\n",
        "                tb_logger.add_scalar(tag='train_loss', scalar_value=loss.item(), global_step=step)\n",
        "                \n",
        "                x, y, prediction = clip_to_uint8(x), clip_to_uint8(y), clip_to_uint8(prediction)\n",
        "                tb_logger.add_images(tag='input', img_tensor=x.to('cpu'), global_step=step)\n",
        "                tb_logger.add_images(tag='target', img_tensor=y.to('cpu'), global_step=step)\n",
        "                tb_logger.add_images(tag='prediction', img_tensor=prediction.to('cpu').detach(), global_step=step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZKSEObbBBns"
      },
      "source": [
        "Validation: we need a metric to evaluate our model besides the loss. One possible quick one is the [Peak signal-to-noise ratio](https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio) will be used from the `scikit-image` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yv3__uABBns"
      },
      "outputs": [],
      "source": [
        "class psnr:\n",
        "    def __call__(self, image_true, image_pred):\n",
        "        image_true = clip_to_uint8(image_true).detach().cpu().numpy()\n",
        "        image_pred = clip_to_uint8(image_pred).detach().cpu().numpy()\n",
        "        return peak_signal_noise_ratio(image_true, image_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPnyse3FBBns"
      },
      "outputs": [],
      "source": [
        "def valid_model(model, loader, criterion, metric, step=None, tb_logger=None):\n",
        "    \n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_metric = 0\n",
        "    \n",
        "    # we are not computing gradients during validation\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            prediction = model(x)\n",
        "            loss = criterion(prediction, y)\n",
        "\n",
        "            val_score = metric(y, prediction)\n",
        "            \n",
        "            val_loss += loss\n",
        "            val_metric += val_score\n",
        "    \n",
        "    # normalize loss and metric\n",
        "    val_loss /= len(loader)\n",
        "    val_metric /= len(loader)\n",
        "    \n",
        "    if tb_logger is not None:\n",
        "        assert step is not None, \"Need to know the current step to log validation results\"\n",
        "        tb_logger.add_scalar(tag='val_loss', scalar_value=val_loss, global_step=step)\n",
        "        tb_logger.add_scalar(tag='val_metric', scalar_value=val_metric, global_step=step)\n",
        "        # we always log the last validation images\n",
        "        x, y, prediction = clip_to_uint8(x), clip_to_uint8(y), clip_to_uint8(prediction)\n",
        "        tb_logger.add_images(tag='val_input', img_tensor=x.to('cpu'), global_step=step)\n",
        "        tb_logger.add_images(tag='val_target', img_tensor=y.to('cpu'), global_step=step)\n",
        "        tb_logger.add_images(tag='val_prediction', img_tensor=prediction.to('cpu'), global_step=step)\n",
        "        \n",
        "    print('\\nValidate: Average loss: {:.4f}, Average Metric: {:.4f}\\n'.format(val_loss, val_metric))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87cJdeFzBBnt"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard summary. \n",
        "# Remember to hit reload in the tensorboad, and check the images\n",
        "# in the settings, you can also set the autoreload option\n",
        "\n",
        "logger = SummaryWriter('runs/noise2noise')\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we have the necessary components to train and validate our Noise2Noise on the VDSR images.\n"
      ],
      "metadata": {
        "id": "dufFyO92QBAJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hpls1GHoBBnt"
      },
      "outputs": [],
      "source": [
        "model = Noise2Noise(in_channels=3, out_channels=3)\n",
        "model = model.to(device)\n",
        "\n",
        "# same parameters as the paper\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "metric = psnr()\n",
        "\n",
        "# start with low number of epochs to check, then increase\n",
        "n_epochs = 5\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_model(model, train_loader, optimizer, criterion, epoch, log_interval=25, tb_logger=logger)\n",
        "    step = epoch * len(train_loader.dataset)\n",
        "    valid_model(model, valid_loader, criterion, metric, step=step, tb_logger=logger)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "You can play with the network, batch size, learning rate, more epochs, etc...\n",
        "Answer the questions below."
      ],
      "metadata": {
        "id": "5XRn4eqWwtB9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rtcfa1NBBnt"
      },
      "source": [
        "4. **Add batch normalization to layers in the Noise2Noise model, and retrain. Compare the behaviour of the loss function.**\n",
        "\n",
        "% your answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Switch the target to be a noiseless image, retrain, and report the PSNR and final loss behaviour with the model trained on noisy images.** \n",
        "\n",
        "% your answer\n",
        "\n"
      ],
      "metadata": {
        "id": "z8_uIS1nSjWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. [Optional] **Train Noise2Noise with a different additive noise model, e.g. Poisson noise with varying $\\lambda$ (you can use `scikit-image`), salt-and-pepper noise, or adding different noise models between source and targets. Show your metrics and a sample of denoised image or in tensorboard** \n",
        "\n",
        "% your answer\n"
      ],
      "metadata": {
        "id": "WAxA--G9Sl5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ywg16UfoPnFN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Copy of PHYS-555-DeepLearningAssignment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7B92r1hDxpXW"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}